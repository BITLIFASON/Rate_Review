Петя — успешный финансист. За много лет практики он выработал успешную систему ведения личных финансов и решил поделиться ей с людьми. Для этого Петя разработал мобильное приложение и выпустил его в онлайн-магазин приложений. После запуска приложения Петя решил собрать отзывы пользователей, чтобы сделать приложение еще более удобным и полезным Петя попросил своего помощника выгрузить отзывы из онлайн-магазина. Но вот незадача из-за ошибки в коде программы у части отзывов получилось выгрузить только текст, а оценки (от 0 до 5) потерялись.

Вам нужно помочь Пете восстановить оценки, которые пользователи поставили приложению, по текстам отзывов. Для этого вам нужно построить модель машинного обучения, которая на основе тренировочной выборки отзывов с оценками обучится восстанавливать оценку (от 0 до 5) по тексту отзыва.

# Формат ввода
Вам даны тренировочная и тестовая выборки данных Тренировочная выборка содержит 4 столбца: 
- id — уникальный идентификатор отзыва,
- review_text — текст отзыва, 
- thumbs_up — количество положительных реакций пользователей на этот отзыв,
- score (целевая переменная) — оценка приложения автора отзыва (от 0 до 5. 0 — ужасно, 5 — отлично).

# Формат вывода
Тестовая выборка содержит первые три столбца. Задача заключается в обучении модели машинного обучения на тренировочных данных и предсказать величину score для тестовых данных. В качестве решения нужно отправить ответы модели на тестовой выборке.

# Примечания
Решение будет оцениваться как задача трехклассовой классификации на классы \[0, 1, 2\], \[3, 4\], \[5\]. Таким образом если ваш ответ "3". а правильный — "4". то ответ засчитывается как верный. Посылка оценивается по метрике _weightedaccuracy_, где веса обратно пропорциональны количеству объектов в каждом классе
Количество баллов за посылку равно
$$\max(0,10 * \frac{accuracy-baseline\_accuracy}{1-baseline\_accuracy})$$
где baseline\_accuracy = 0.33. a accuracy - результат

# Решение
Первая попытка была fine-tuning BERT'а (с обучением только классификатора) \[обучался около 3.5 часов с конечным прерыванием\], но прирост accuracy был очень малым \[на валидации - 1%\] и она дала 0 баллов. Далее была попытка обучить RMDL (Random Multimodel Deep Learning), но это дало около 1.5 балла. В итоге была создана свёрточная сеть с эмбидингами из Word2Vec и обучена на 5 эпохах, и несмотря на сильное переобучение она дала 5.31 балла => accuracy на тесте около 0.686.

Возможно настройка CNN и обучение всех слоёв BERT'а дали бы результат лучше, но к сожалению время на выполнение заданий олимпиады подходило к концу.
