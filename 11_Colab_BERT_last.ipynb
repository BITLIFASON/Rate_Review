{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ddb3fedd",
      "metadata": {
        "id": "ddb3fedd"
      },
      "source": [
        "# IMPORT, CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X23O5hpN6ymK",
        "outputId": "0930e136-1c6c-44e0-fe24-ea3818c00c44"
      },
      "id": "X23O5hpN6ymK",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by8GGX2563NK",
        "outputId": "56fe6022-4dd1-4478-f4b1-e36720ee6862"
      },
      "id": "by8GGX2563NK",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.8/dist-packages (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1f6d41c6",
      "metadata": {
        "id": "1f6d41c6"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, AutoTokenizer,logging\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import gensim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "50a776f7",
      "metadata": {
        "id": "50a776f7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 8, 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f5679a0b",
      "metadata": {
        "id": "f5679a0b"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.random.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.random.manual_seed_all(RANDOM_SEED)\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b32bac37",
      "metadata": {
        "id": "b32bac37"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3994ee96",
      "metadata": {
        "id": "3994ee96"
      },
      "source": [
        "# LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Professional11')"
      ],
      "metadata": {
        "id": "9eySWylK69wJ"
      },
      "id": "9eySWylK69wJ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1f2ae507",
      "metadata": {
        "id": "1f2ae507"
      },
      "outputs": [],
      "source": [
        "target_dir = \"./output_bert_Ohsumed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2b90db41",
      "metadata": {
        "id": "2b90db41"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('./train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "55c47728",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "55c47728",
        "outputId": "37ad1203-3a2e-4d71-f9c1-b3b5b2cd0a52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id                                        review_text  thumbs_up  \\\n",
              "0            0  It provides latest informations. Easy to use. ...          0   \n",
              "1            1                                      Good service.          0   \n",
              "2            2                     Looks great and simple to use.          0   \n",
              "3            3  Clear stats, everthing you need to know at a g...          0   \n",
              "4            4                                      Very good app          0   \n",
              "...        ...                                                ...        ...   \n",
              "127628  127628               5yr/ longer timeframe charts please.          1   \n",
              "127629  127629                                    My morning app.          0   \n",
              "127630  127630             Changes in the portfolio isn't working          2   \n",
              "127631  127631  Literal scum company, screwing over the little...         22   \n",
              "127632  127632   It puts the market at my finger tips. Thank you.          0   \n",
              "\n",
              "        score  \n",
              "0           5  \n",
              "1           4  \n",
              "2           4  \n",
              "3           4  \n",
              "4           5  \n",
              "...       ...  \n",
              "127628      2  \n",
              "127629      5  \n",
              "127630      2  \n",
              "127631      1  \n",
              "127632      5  \n",
              "\n",
              "[127633 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81e77fba-563f-48ab-8b31-5ba2a9c84a21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>thumbs_up</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>It provides latest informations. Easy to use. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Good service.</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Looks great and simple to use.</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Clear stats, everthing you need to know at a g...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Very good app</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127628</th>\n",
              "      <td>127628</td>\n",
              "      <td>5yr/ longer timeframe charts please.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127629</th>\n",
              "      <td>127629</td>\n",
              "      <td>My morning app.</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127630</th>\n",
              "      <td>127630</td>\n",
              "      <td>Changes in the portfolio isn't working</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127631</th>\n",
              "      <td>127631</td>\n",
              "      <td>Literal scum company, screwing over the little...</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127632</th>\n",
              "      <td>127632</td>\n",
              "      <td>It puts the market at my finger tips. Thank you.</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>127633 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81e77fba-563f-48ab-8b31-5ba2a9c84a21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81e77fba-563f-48ab-8b31-5ba2a9c84a21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81e77fba-563f-48ab-8b31-5ba2a9c84a21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e781bdea",
      "metadata": {
        "id": "e781bdea"
      },
      "outputs": [],
      "source": [
        "test_data_source = pd.read_csv('./test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "5f0cc1a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5f0cc1a5",
        "outputId": "a6af186d-5045-4fd5-f0d2-958d61f53777"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                        review_text  thumbs_up\n",
              "0      127633  I didnt expect it to be real. But just played ...          0\n",
              "1      127634      Ver convinent app, good information and news.          2\n",
              "2      127635            Plots of info and stock proces for free          1\n",
              "3      127636  Easy to use, and very helpful for maintaining ...         52\n",
              "4      127637                  Easy to use, lots of information.          1\n",
              "...       ...                                                ...        ...\n",
              "31904  159537  I lke Mint a lot, but for me it does not provi...          1\n",
              "31905  159538                Why do you ask for my phone number?          0\n",
              "31906  159539  Great for keeping up with stocks, I use it daily.          0\n",
              "31907  159540        gives relevant market news. easy to follow.          2\n",
              "31908  159541                      Didn't work with my bank USAA          0\n",
              "\n",
              "[31909 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b34c353d-147e-483d-8169-e6c17034398c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>thumbs_up</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127633</td>\n",
              "      <td>I didnt expect it to be real. But just played ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127634</td>\n",
              "      <td>Ver convinent app, good information and news.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>127635</td>\n",
              "      <td>Plots of info and stock proces for free</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127636</td>\n",
              "      <td>Easy to use, and very helpful for maintaining ...</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>127637</td>\n",
              "      <td>Easy to use, lots of information.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31904</th>\n",
              "      <td>159537</td>\n",
              "      <td>I lke Mint a lot, but for me it does not provi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31905</th>\n",
              "      <td>159538</td>\n",
              "      <td>Why do you ask for my phone number?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31906</th>\n",
              "      <td>159539</td>\n",
              "      <td>Great for keeping up with stocks, I use it daily.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31907</th>\n",
              "      <td>159540</td>\n",
              "      <td>gives relevant market news. easy to follow.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31908</th>\n",
              "      <td>159541</td>\n",
              "      <td>Didn't work with my bank USAA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31909 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b34c353d-147e-483d-8169-e6c17034398c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b34c353d-147e-483d-8169-e6c17034398c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b34c353d-147e-483d-8169-e6c17034398c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "test_data_source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ae790188",
      "metadata": {
        "id": "ae790188"
      },
      "outputs": [],
      "source": [
        "target_column = 'score'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4df6dc26",
      "metadata": {
        "id": "4df6dc26"
      },
      "outputs": [],
      "source": [
        "train_df, non_train_df = train_test_split(train_data, test_size=0.2, random_state=RANDOM_SEED,stratify=train_data[target_column].to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "92f6f0f2",
      "metadata": {
        "id": "92f6f0f2"
      },
      "outputs": [],
      "source": [
        "dev_df, test_df = train_test_split(non_train_df, test_size=0.5, random_state=RANDOM_SEED,stratify=non_train_df[target_column].to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "479d7fe3",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "479d7fe3",
        "outputId": "e94c8846-2f63-480e-d538-972156d9bce1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102106, 12763, 12764)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(train_df), len(dev_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "423d5784",
      "metadata": {
        "id": "423d5784"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(target_dir):\n",
        "    os.makedirs(target_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c79f55c",
      "metadata": {
        "id": "2c79f55c"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1d0351ea",
      "metadata": {
        "id": "1d0351ea"
      },
      "outputs": [],
      "source": [
        "class BertModel(nn.Module):\n",
        "    def __init__(self, requires_grad = False):\n",
        "        super(BertModel, self).__init__()\n",
        "        self.bert = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME,num_labels = len(train_data.groupby('score').count().index))\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=True)\n",
        "        self.requires_grad = requires_grad\n",
        "        self.device = torch.device(DEVICE)\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = requires_grad  # Each parameter requires gradient\n",
        "\n",
        "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, labels):\n",
        "        loss, logits = self.bert(input_ids = batch_seqs, attention_mask = batch_seq_masks, \n",
        "                              token_type_ids=batch_seq_segments, labels = labels)[:2]\n",
        "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
        "        return loss, logits, probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3be489e6",
      "metadata": {
        "id": "3be489e6"
      },
      "outputs": [],
      "source": [
        "bertmodel = BertModel(requires_grad = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4f91e74e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f91e74e",
        "outputId": "dc2a3588-3c87-447b-a977-738bc87f6946"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=====================================================================================\n",
              "Layer (type:depth-idx)                                       Param #\n",
              "=====================================================================================\n",
              "BertModel                                                    --\n",
              "├─BertForSequenceClassification: 1-1                         --\n",
              "│    └─BertModel: 2-1                                        --\n",
              "│    │    └─BertEmbeddings: 3-1                              (23,837,184)\n",
              "│    │    └─BertEncoder: 3-2                                 (85,054,464)\n",
              "│    │    └─BertPooler: 3-3                                  (590,592)\n",
              "│    └─Dropout: 2-2                                          --\n",
              "│    └─Linear: 2-3                                           (4,614)\n",
              "=====================================================================================\n",
              "Total params: 109,486,854\n",
              "Trainable params: 0\n",
              "Non-trainable params: 109,486,854\n",
              "====================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "summary(bertmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9b51fd62",
      "metadata": {
        "id": "9b51fd62"
      },
      "outputs": [],
      "source": [
        "for name, param in bertmodel.bert.named_parameters():\n",
        "    if name == 'classifier.weight' or name == 'classifier.bias':\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "268740d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "268740d2",
        "outputId": "f4062e43-b435-46eb-bf90-235d8a852d5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "bertmodel.bert.base_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b23874d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b23874d1",
        "outputId": "d6492d68-14dd-4547-ee51-3c5ee879d029"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=6, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "bertmodel.bert.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "47ddbfea",
      "metadata": {
        "id": "47ddbfea"
      },
      "outputs": [],
      "source": [
        "model = bertmodel.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2378fa2a",
      "metadata": {
        "id": "2378fa2a"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "da0e7178",
      "metadata": {
        "id": "da0e7178"
      },
      "outputs": [],
      "source": [
        "tokenizer = bertmodel.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bc13ba86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc13ba86",
        "outputId": "9dea1bc3-f9d5-4833-cf98-fd4bdfeeb97e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', 102)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "tokenizer.sep_token, tokenizer.sep_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f06d0b7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f06d0b7a",
        "outputId": "254003a1-8790-4835-c8be-ad36064fe2a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', 101)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "tokenizer.cls_token, tokenizer.cls_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3d765a25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d765a25",
        "outputId": "a997b181-22c0-4c66-db91-241e00bee411"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "tokenizer.pad_token, tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eec47c7",
      "metadata": {
        "id": "4eec47c7"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ceb7cc1f",
      "metadata": {
        "id": "ceb7cc1f"
      },
      "outputs": [],
      "source": [
        "class DataPrecessForSentence(Dataset):\n",
        "    \"\"\"\n",
        "    Encoding sentences\n",
        "    \"\"\"\n",
        "    def __init__(self, bert_tokenizer, df, max_seq_len = 50):\n",
        "        super(DataPrecessForSentence, self).__init__()\n",
        "        self.bert_tokenizer = bert_tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.input_ids, self.attention_mask, self.token_type_ids, self.labels = self.get_input(df)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attention_mask[idx], self.token_type_ids[idx], self.labels[idx]\n",
        "        \n",
        "    # Convert dataframe to tensor\n",
        "    def get_input(self, df):\n",
        "        sentences = df['review_text'].values\n",
        "        labels = df[target_column].values\n",
        "        \n",
        "        # tokenizer\n",
        "        tokens_seq = list(map(self.bert_tokenizer.tokenize, sentences)) # list of shape [sentence_len, token_len]\n",
        "        \n",
        "        # Get fixed-length sequence and its mask\n",
        "        result = list(map(self.trunate_and_pad, tokens_seq))\n",
        "        \n",
        "        input_ids = [i[0] for i in result]\n",
        "        attention_mask = [i[1] for i in result]\n",
        "        token_type_ids = [i[2] for i in result]\n",
        "        \n",
        "        return (\n",
        "               torch.Tensor(input_ids).type(torch.long), \n",
        "               torch.Tensor(attention_mask).type(torch.long),\n",
        "               torch.Tensor(token_type_ids).type(torch.long), \n",
        "               torch.Tensor(labels).type(torch.long)\n",
        "               )\n",
        "    \n",
        "    \n",
        "    def trunate_and_pad(self, tokens_seq):\n",
        "        \n",
        "        # Concat '[CLS]' at the beginning\n",
        "        tokens_seq = ['[CLS]'] + tokens_seq     \n",
        "        # Truncate sequences of which the lengths exceed the max_seq_len\n",
        "        if len(tokens_seq) > self.max_seq_len:\n",
        "            tokens_seq = tokens_seq[0 : self.max_seq_len]           \n",
        "        # Generate padding\n",
        "        padding = [0] * (self.max_seq_len - len(tokens_seq))       \n",
        "        # Convert tokens_seq to token_ids\n",
        "        input_ids = self.bert_tokenizer.convert_tokens_to_ids(tokens_seq)\n",
        "        input_ids += padding   \n",
        "        # Create attention_mask\n",
        "        attention_mask = [1] * len(tokens_seq) + padding     \n",
        "        # Create token_type_ids\n",
        "        token_type_ids = [0] * (self.max_seq_len)\n",
        "        \n",
        "        assert len(input_ids) == self.max_seq_len\n",
        "        assert len(attention_mask) == self.max_seq_len\n",
        "        assert len(token_type_ids) == self.max_seq_len\n",
        "        \n",
        "        return input_ids, attention_mask, token_type_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c7beaf01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7beaf01",
        "outputId": "b3bf22cd-7dbc-4d71-cc46-8317ad8e1863"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# sentences = (train_df['review_text'].values, dev_df['review_text'].values, test_df['review_text'].values)\n",
        "# sp = (list(map(tokenizer.tokenize, sentences[0])), list(map(tokenizer.tokenize, sentences[1])), list(map(tokenizer.tokenize, sentences[2])))\n",
        "# len_sp = (list(map(len,sp[0])),list(map(len,sp[1])),list(map(len,sp[2])))\n",
        "# max_sp = max(len_sp[0]), max(len_sp[1]), max(len_sp[2])\n",
        "# if max(max_sp) > 512:\n",
        "#     MAX_LEN = 512\n",
        "# else:\n",
        "#     MAX_LEM = max(max_sp)\n",
        "# del sentences, sp, len_sp, max_sp\n",
        "MAX_LEN = 512\n",
        "MAX_LEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5b9c381b",
      "metadata": {
        "id": "5b9c381b"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "db04e6d1",
      "metadata": {
        "id": "db04e6d1"
      },
      "outputs": [],
      "source": [
        "train_data = DataPrecessForSentence(tokenizer, train_df, max_seq_len = MAX_LEN)\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3f97da2a",
      "metadata": {
        "id": "3f97da2a"
      },
      "outputs": [],
      "source": [
        "dev_data = DataPrecessForSentence(tokenizer,dev_df, max_seq_len = MAX_LEN)\n",
        "dev_loader = DataLoader(dev_data, shuffle=True, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9536177a",
      "metadata": {
        "id": "9536177a"
      },
      "outputs": [],
      "source": [
        "test_data = DataPrecessForSentence(tokenizer,test_df, max_seq_len = MAX_LEN)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24ebfb71",
      "metadata": {
        "id": "24ebfb71"
      },
      "source": [
        "# TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "89e27090",
      "metadata": {
        "id": "89e27090"
      },
      "outputs": [],
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "LR = 2e-05\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "    'params':[p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay':0.01\n",
        "    },\n",
        "    {\n",
        "    'params':[p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay':0.0\n",
        "    }\n",
        "]\n",
        "optimizer = optim.AdamW(optimizer_grouped_parameters, lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "bb07d797",
      "metadata": {
        "id": "bb07d797"
      },
      "outputs": [],
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.85, patience=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "7e1d8f4c",
      "metadata": {
        "id": "7e1d8f4c"
      },
      "outputs": [],
      "source": [
        "def Metric(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    compute and show the classification result\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    macro_precision = precision_score(y_true, y_pred, average='macro')\n",
        "    macro_recall = recall_score(y_true, y_pred, average='macro')\n",
        "    weighted_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    target_names = [f'class_{i}' for i in range(all_prob[0].shape[0])]\n",
        "    report = classification_report(y_true, y_pred, target_names=target_names, digits=3)\n",
        "\n",
        "    print('Accuracy: {:.1%}\\nPrecision: {:.1%}\\nRecall: {:.1%}\\nF1: {:.1%}'.format(accuracy, macro_precision,\n",
        "                                           macro_recall, weighted_f1))\n",
        "    print(\"classification_report:\\n\")\n",
        "    print(report)\n",
        "  \n",
        "  \n",
        "def correct_predictions(output_probabilities, targets):\n",
        "    \"\"\"\n",
        "    Compute the number of predictions that match some target classes in the\n",
        "    output of a model.\n",
        "    Args:\n",
        "        output_probabilities: A tensor of probabilities for different output\n",
        "            classes.\n",
        "        targets: The indices of the actual target classes.\n",
        "    Returns:\n",
        "        The number of correct predictions in 'output_probabilities'.\n",
        "    \"\"\"\n",
        "    _, out_classes = output_probabilities.max(dim=1)\n",
        "    correct = (out_classes == targets).sum()\n",
        "    return correct.item()\n",
        "\n",
        "\n",
        "def train(model, dataloader, optimizer, epoch_number, max_gradient_norm):\n",
        "    \"\"\"\n",
        "    Train a model for one epoch on some input data with a given optimizer and\n",
        "    criterion.\n",
        "    Args:\n",
        "        model: A torch module that must be trained on some input data.\n",
        "        dataloader: A DataLoader object to iterate over the training data.\n",
        "        optimizer: A torch optimizer to use for training on the input model.\n",
        "        epoch_number: The number of the epoch for which training is performed.\n",
        "        max_gradient_norm: Max. norm for gradient norm clipping.\n",
        "    Returns:\n",
        "        epoch_time: The total time necessary to train the epoch.\n",
        "        epoch_loss: The training loss computed for the epoch.\n",
        "        epoch_accuracy: The accuracy computed for the epoch.\n",
        "    \"\"\"\n",
        "    # Switch the model to train mode.\n",
        "    model.train()\n",
        "    device = model.device\n",
        "    epoch_start = time.time()\n",
        "    batch_time_avg = 0.0\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    tqdm_batch_iterator = tqdm(dataloader)\n",
        "    for batch_index, (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in enumerate(tqdm_batch_iterator):\n",
        "        batch_start = time.time()\n",
        "        seqs, masks, segments, labels = batch_seqs.to(device), batch_seq_masks.to(device), batch_seq_segments.to(device), batch_labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss, logits, probabilities = model(seqs, masks, segments, labels)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
        "        optimizer.step()\n",
        "        batch_time_avg += time.time() - batch_start\n",
        "        running_loss += loss.item()\n",
        "        correct_preds += correct_predictions(probabilities, labels)\n",
        "        description = \"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\\\n",
        "                      .format(batch_time_avg/(batch_index+1), running_loss/(batch_index+1))\n",
        "        tqdm_batch_iterator.set_description(description)\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_accuracy = correct_preds / len(dataloader.dataset)\n",
        "    return epoch_time, epoch_loss, epoch_accuracy\n",
        "\n",
        "\n",
        "def validate(model, dataloader):\n",
        "    \"\"\"\n",
        "    Compute the loss and accuracy of a model on some validation dataset.\n",
        "    Args:\n",
        "        model: A torch module for which the loss and accuracy must be\n",
        "            computed.\n",
        "        dataloader: A DataLoader object to iterate over the validation data.\n",
        "    Returns:\n",
        "        epoch_time: The total time to compute the loss and accuracy on the\n",
        "            entire validation set.\n",
        "        epoch_loss: The loss computed on the entire validation set.\n",
        "        epoch_accuracy: The accuracy computed on the entire validation set.\n",
        "        roc_auc_score(all_labels, all_prob): The auc computed on the entire validation set.\n",
        "        all_prob: The probability of classification as label 1 on the entire validation set.\n",
        "    \"\"\"\n",
        "    # Switch to evaluate mode.\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    epoch_start = time.time()\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "    all_prob = []\n",
        "    all_labels = []\n",
        "    # Deactivate autograd for evaluation.\n",
        "    with torch.no_grad():\n",
        "        for (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in dataloader:\n",
        "            # Move input and output data to the GPU if one is used.\n",
        "            seqs = batch_seqs.to(device)\n",
        "            masks = batch_seq_masks.to(device)\n",
        "            segments = batch_seq_segments.to(device)\n",
        "            labels = batch_labels.to(device)\n",
        "            loss, logits, probabilities = model(seqs, masks, segments, labels)\n",
        "            running_loss += loss.item()\n",
        "            running_accuracy += correct_predictions(probabilities, labels)\n",
        "            all_prob.extend(probabilities.cpu().numpy())\n",
        "            all_labels.extend(batch_labels)\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_accuracy = running_accuracy / (len(dataloader.dataset))\n",
        "    return epoch_time, epoch_loss, epoch_accuracy, all_prob\n",
        "\n",
        "def test(model, dataloader):\n",
        "    \"\"\"\n",
        "    Test the accuracy of a model on some labelled test dataset.\n",
        "    Args:\n",
        "        model: The torch module on which testing must be performed.\n",
        "        dataloader: A DataLoader object to iterate over some dataset.\n",
        "    Returns:\n",
        "        batch_time: The average time to predict the classes of a batch.\n",
        "        total_time: The total time to process the whole dataset.\n",
        "        accuracy: The accuracy of the model on the input data.\n",
        "        all_prob: The probability of classification as label 1 on the entire validation set.\n",
        "    \"\"\"\n",
        "    # Switch the model to eval mode.\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    time_start = time.time()\n",
        "    batch_time = 0.0\n",
        "    accuracy = 0.0\n",
        "    all_prob = []\n",
        "    all_labels = []\n",
        "    # Deactivate autograd for evaluation.\n",
        "    with torch.no_grad():\n",
        "        for (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in dataloader:\n",
        "            batch_start = time.time()\n",
        "            # Move input and output data to the GPU if one is used.\n",
        "            seqs, masks, segments, labels = batch_seqs.to(device), batch_seq_masks.to(device), batch_seq_segments.to(device), batch_labels.to(device)\n",
        "            _, _, probabilities = model(seqs, masks, segments, labels)\n",
        "            accuracy += correct_predictions(probabilities, labels)\n",
        "            batch_time += time.time() - batch_start\n",
        "            all_prob.extend(probabilities.cpu().numpy())\n",
        "            all_labels.extend(batch_labels)\n",
        "    batch_time /= len(dataloader)\n",
        "    total_time = time.time() - time_start\n",
        "    accuracy /= (len(dataloader.dataset))\n",
        "\n",
        "    return batch_time, total_time, accuracy, all_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "47671a43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "47671a43",
        "outputId": "69b991fa-d8d0-423b-998d-716efd5444ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "* Validation loss before training: 1.6113, accuracy: 52.3701%\n",
            "\n",
            " ==================== Training bert model on device: cuda ====================\n",
            "* Training epoch 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Avg. batch proc. time: 0.0172s, loss: 1.3439: 100%|██████████| 681/681 [58:30<00:00,  5.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Training time: 3510.9296s, loss = 1.3439, accuracy: 53.5532%\n",
            "* Validation for epoch 1:\n",
            "-> Valid. time: 417.6336s, loss: 1.2399, accuracy: 54.5013%\n",
            "\n",
            "save model succesfully!\n",
            "\n",
            "* Test for epoch 1:\n",
            "Test accuracy: 0.5451%\n",
            "\n",
            "* Training epoch 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Avg. batch proc. time: 0.0168s, loss: 1.2447: 100%|██████████| 681/681 [58:27<00:00,  5.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Training time: 3507.6975s, loss = 1.2447, accuracy: 54.4131%\n",
            "* Validation for epoch 2:\n",
            "-> Valid. time: 416.6478s, loss: 1.2060, accuracy: 54.6502%\n",
            "\n",
            "save model succesfully!\n",
            "\n",
            "* Test for epoch 2:\n",
            "Test accuracy: 0.5468%\n",
            "\n",
            "* Training epoch 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Avg. batch proc. time: 0.0172s, loss: 1.2149: 100%|██████████| 681/681 [58:29<00:00,  5.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Training time: 3509.4676s, loss = 1.2149, accuracy: 54.7108%\n",
            "* Validation for epoch 3:\n",
            "-> Valid. time: 417.8606s, loss: 1.1844, accuracy: 55.2691%\n",
            "\n",
            "save model succesfully!\n",
            "\n",
            "* Test for epoch 3:\n",
            "Test accuracy: 0.5529%\n",
            "\n",
            "* Training epoch 4:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Avg. batch proc. time: 0.0168s, loss: 1.1996:  32%|███▏      | 221/681 [19:04<39:43,  5.18s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-cc767853e937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"* Training epoch {}:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mepoch_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-d49b84326284>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, epoch_number, max_gradient_norm)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbatch_time_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mcorrect_preds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrect_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_score = 0.0\n",
        "epochs=10\n",
        "start_epoch = 1\n",
        "patience = 1\n",
        "max_grad_norm = 10.0\n",
        "if_save_model = True\n",
        "checkpoint = None\n",
        "\n",
        "# Data for loss curves plot\n",
        "epochs_count = []\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "valid_losses = []\n",
        "valid_accuracies = []\n",
        "\n",
        "if checkpoint:\n",
        "    checkpoint = torch.load(checkpoint)\n",
        "    start_epoch = checkpoint[\"epoch\"] + 1\n",
        "    best_score = checkpoint[\"best_score\"]\n",
        "    print(\"\\t* Training will continue on existing model from epoch {}...\".format(start_epoch))\n",
        "    model.load_state_dict(checkpoint[\"model\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "    epochs_count = checkpoint[\"epochs_count\"]\n",
        "    train_losses = checkpoint[\"train_losses\"]\n",
        "    train_accuracy = checkpoint[\"train_accuracy\"]\n",
        "    valid_losses = checkpoint[\"valid_losses\"]\n",
        "    valid_accuracy = checkpoint[\"valid_accuracy\"]\n",
        "\n",
        " # Compute loss and accuracy before starting (or resuming) training.\n",
        "_, valid_loss, valid_accuracy,  _, = validate(model, dev_loader)\n",
        "print(\"\\n* Validation loss before training: {:.4f}, accuracy: {:.4f}%\".format(valid_loss, (valid_accuracy*100)))\n",
        "\n",
        "# -------------------- Training epochs -----------------------------------#\n",
        "\n",
        "print(\"\\n\", 20 * \"=\", \"Training bert model on device: {}\".format(DEVICE), 20 * \"=\")\n",
        "patience_counter = 0\n",
        "for epoch in range(start_epoch, epochs + 1):\n",
        "    epochs_count.append(epoch)\n",
        "\n",
        "    print(\"* Training epoch {}:\".format(epoch))\n",
        "    epoch_time, epoch_loss, epoch_accuracy = train(model, train_loader, optimizer, epoch, max_grad_norm)\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_accuracy)  \n",
        "    print(\"-> Training time: {:.4f}s, loss = {:.4f}, accuracy: {:.4f}%\".format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
        "\n",
        "    print(\"* Validation for epoch {}:\".format(epoch))\n",
        "    epoch_time, epoch_loss, epoch_accuracy, _, = validate(model, dev_loader)\n",
        "    valid_losses.append(epoch_loss)\n",
        "    valid_accuracies.append(epoch_accuracy)\n",
        "    print(\"-> Valid. time: {:.4f}s, loss: {:.4f}, accuracy: {:.4f}%\\n\"\n",
        "          .format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
        "\n",
        "    # Update the optimizer's learning rate with the scheduler.\n",
        "    scheduler.step(epoch_accuracy)\n",
        "    ## scheduler.step()\n",
        "\n",
        "    # Early stopping on validation accuracy.\n",
        "    if epoch_accuracy < best_score:\n",
        "        patience_counter += 1\n",
        "    else:\n",
        "        best_score = epoch_accuracy\n",
        "        patience_counter = 0\n",
        "        if (if_save_model):\n",
        "            torch.save({\"epoch\": epoch, \n",
        "                       \"model\": model.state_dict(),\n",
        "                       \"optimizer\": optimizer.state_dict(),\n",
        "                       \"best_score\": best_score,\n",
        "                       \"epochs_count\": epochs_count,\n",
        "                       \"train_losses\": train_losses,\n",
        "                       \"train_accuracy\": train_accuracies,\n",
        "                       \"valid_losses\": valid_losses,\n",
        "                       \"valid_accuracy\": valid_accuracies,\n",
        "                       },\n",
        "                       os.path.join(target_dir, \"best.pth.tar\"))\n",
        "            print(\"save model succesfully!\\n\")\n",
        "\n",
        "        # run model on test set and save the prediction result to csv\n",
        "        print(\"* Test for epoch {}:\".format(epoch))\n",
        "        _, _, test_accuracy, all_prob = validate(model, test_loader)\n",
        "        print(\"Test accuracy: {:.4f}%\\n\".format(test_accuracy))\n",
        "        columns_names = [f'prob_{i}' for i in range(all_prob[0].shape[0])]\n",
        "        test_prediction = pd.DataFrame(all_prob,columns=columns_names)\n",
        "        test_prediction['prediction'] = test_prediction.apply(lambda x: columns_names.index(x.idxmax()) , axis=1)\n",
        "        test_prediction = test_prediction[[*columns_names, 'prediction']]\n",
        "        test_prediction.to_csv(os.path.join(target_dir,\"test_prediction.csv\"), index=False,sep=';')\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(\"-> Early stopping: patience limit reached, stopping...\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "fdcf9fd8",
      "metadata": {
        "id": "fdcf9fd8"
      },
      "outputs": [],
      "source": [
        "test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'),sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "eb48371f",
      "metadata": {
        "id": "eb48371f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60e33d6-8421-4164-a27c-a3e110659e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 55.3%\n",
            "Precision: 16.1%\n",
            "Recall: 17.8%\n",
            "F1: 13.9%\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class_0      0.000     0.000     0.000         5\n",
            "     class_1      0.407     0.072     0.123      1760\n",
            "     class_2      0.000     0.000     0.000       715\n",
            "     class_3      0.000     0.000     0.000       885\n",
            "     class_4      0.000     0.000     0.000      2439\n",
            "     class_5      0.557     0.996     0.714      6960\n",
            "\n",
            "    accuracy                          0.553     12764\n",
            "   macro avg      0.161     0.178     0.139     12764\n",
            "weighted avg      0.360     0.553     0.406     12764\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Metric(test_df[target_column], test_result.prediction) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "386624ce",
      "metadata": {
        "id": "386624ce"
      },
      "outputs": [],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPrecessForSentenceTest(Dataset):\n",
        "    \"\"\"\n",
        "    Encoding sentences\n",
        "    \"\"\"\n",
        "    def __init__(self, bert_tokenizer, df, max_seq_len = 50):\n",
        "        super(DataPrecessForSentenceTest, self).__init__()\n",
        "        self.bert_tokenizer = bert_tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.input_ids, self.attention_mask, self.token_type_ids, self.labels = self.get_input(df)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attention_mask[idx], self.token_type_ids[idx], self.labels[idx]\n",
        "        \n",
        "    # Convert dataframe to tensor\n",
        "    def get_input(self, df):\n",
        "        sentences = df['review_text'].values\n",
        "        labels = np.zeros(len(sentences))\n",
        "        \n",
        "        # tokenizer\n",
        "        tokens_seq = list(map(self.bert_tokenizer.tokenize, sentences)) # list of shape [sentence_len, token_len]\n",
        "        \n",
        "        # Get fixed-length sequence and its mask\n",
        "        result = list(map(self.trunate_and_pad, tokens_seq))\n",
        "        \n",
        "        input_ids = [i[0] for i in result]\n",
        "        attention_mask = [i[1] for i in result]\n",
        "        token_type_ids = [i[2] for i in result]\n",
        "        \n",
        "        return (\n",
        "               torch.Tensor(input_ids).type(torch.long), \n",
        "               torch.Tensor(attention_mask).type(torch.long),\n",
        "               torch.Tensor(token_type_ids).type(torch.long), \n",
        "               torch.Tensor(labels).type(torch.long)\n",
        "               )\n",
        "    \n",
        "    \n",
        "    def trunate_and_pad(self, tokens_seq):\n",
        "        \n",
        "        # Concat '[CLS]' at the beginning\n",
        "        tokens_seq = ['[CLS]'] + tokens_seq     \n",
        "        # Truncate sequences of which the lengths exceed the max_seq_len\n",
        "        if len(tokens_seq) > self.max_seq_len:\n",
        "            tokens_seq = tokens_seq[0 : self.max_seq_len]           \n",
        "        # Generate padding\n",
        "        padding = [0] * (self.max_seq_len - len(tokens_seq))       \n",
        "        # Convert tokens_seq to token_ids\n",
        "        input_ids = self.bert_tokenizer.convert_tokens_to_ids(tokens_seq)\n",
        "        input_ids += padding   \n",
        "        # Create attention_mask\n",
        "        attention_mask = [1] * len(tokens_seq) + padding     \n",
        "        # Create token_type_ids\n",
        "        token_type_ids = [0] * (self.max_seq_len)\n",
        "        \n",
        "        assert len(input_ids) == self.max_seq_len\n",
        "        assert len(attention_mask) == self.max_seq_len\n",
        "        assert len(token_type_ids) == self.max_seq_len\n",
        "        \n",
        "        return input_ids, attention_mask, token_type_ids"
      ],
      "metadata": {
        "id": "onRJpHqmifpR"
      },
      "id": "onRJpHqmifpR",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = DataPrecessForSentenceTest(tokenizer,test_data_source, max_seq_len = MAX_LEN)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "xiOhj_v9i9bZ"
      },
      "id": "xiOhj_v9i9bZ",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test1(model, dataloader):\n",
        "    \"\"\"\n",
        "    Test the accuracy of a model on some labelled test dataset.\n",
        "    Args:\n",
        "        model: The torch module on which testing must be performed.\n",
        "        dataloader: A DataLoader object to iterate over some dataset.\n",
        "    Returns:\n",
        "        batch_time: The average time to predict the classes of a batch.\n",
        "        total_time: The total time to process the whole dataset.\n",
        "        accuracy: The accuracy of the model on the input data.\n",
        "        all_prob: The probability of classification as label 1 on the entire validation set.\n",
        "    \"\"\"\n",
        "    # Switch the model to eval mode.\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    time_start = time.time()\n",
        "    batch_time = 0.0\n",
        "    accuracy = 0.0\n",
        "    all_prob = []\n",
        "    all_labels = []\n",
        "    # Deactivate autograd for evaluation.\n",
        "    with torch.no_grad():\n",
        "        for (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in dataloader:\n",
        "            batch_start = time.time()\n",
        "            # Move input and output data to the GPU if one is used.\n",
        "            seqs, masks, segments, labels = batch_seqs.to(device), batch_seq_masks.to(device), batch_seq_segments.to(device), batch_labels.to(device)\n",
        "            _, _, probabilities = model(seqs, masks, segments, labels)\n",
        "            accuracy += correct_predictions(probabilities, labels)\n",
        "            batch_time += time.time() - batch_start\n",
        "            all_prob.extend(probabilities.cpu().numpy())\n",
        "            all_labels.extend(batch_labels)\n",
        "    batch_time /= len(dataloader)\n",
        "    total_time = time.time() - time_start\n",
        "    accuracy /= (len(dataloader.dataset))\n",
        "\n",
        "    return batch_time, total_time, accuracy, all_prob"
      ],
      "metadata": {
        "id": "wYUgGWt8i9de"
      },
      "id": "wYUgGWt8i9de",
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, test_accuracy, all_prob = test1(model, test_loader)"
      ],
      "metadata": {
        "id": "cTYWdkValKJK"
      },
      "id": "cTYWdkValKJK",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = pd.DataFrame(all_prob,columns=columns_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "ge6jwDvEkjlw",
        "outputId": "8b343d41-c168-4efe-80f1-f558c6cf235b"
      },
      "id": "ge6jwDvEkjlw",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d6da5b66315b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_prediction = pd.DataFrame({'score':test_prediction.apply(lambda x: columns_names.index(x.idxmax()) , axis=1)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Jx4vvKcXnAh0",
        "outputId": "e7e2ddd2-bbae-49a9-e0a7-080fb2bcf0a3"
      },
      "id": "Jx4vvKcXnAh0",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e0ffc22aa892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcolumns_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_prediction.to_csv('MySubmission.csv',index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "PaRs_38FmXJP",
        "outputId": "eba0e27f-d6ed-48e7-cac0-d0707bd6ebce"
      },
      "id": "PaRs_38FmXJP",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d7ad5773e709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MySubmission.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'my_prediction' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WqeCIh3imbP1"
      },
      "id": "WqeCIh3imbP1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}